# task
task_cls: ''
work_dir: '' # experiment directory.
infer: false # infer
seed: 1234
debug: false
save_codes:
  - configs
  - modules
  - training
  - utils

#############
# dataset
#############
sort_by_len: true
raw_data_dir: ''
binary_data_dir: ''
binarizer_cls: ''
binarization_args:
  shuffle: false
  num_workers: 0

audio_num_mel_bins: 80
audio_sample_rate: 22050
hop_size: 256  # For 22050Hz, 275 ~= 12.5 ms (0.0125 * sample_rate)
win_size: 1024  # For 22050Hz, 1100 ~= 50 ms (If None, win_size: fft_size) (0.05 * sample_rate)
fmin: 80  # Set this to 55 if your speaker is male! if female, 95 should help taking off noise. (To test depending on dataset. Pitch info: male~[65, 260], female~[100, 525])
fmax: 7600  # To be increased/reduced depending on data.
fft_size: 1024  # Extra window size is filled with 0 paddings to match this parameter
num_spk: 1
mel_vmin: -6
mel_vmax: 1.5
sampler_frame_count_grid: 6
ds_workers: 4
dataloader_prefetch_factor: 2

#########
# model
#########
hidden_size: 256
dropout: 0.1
use_pos_embed: true
enc_layers: 4
num_heads: 2
enc_ffn_kernel_size: 9
ffn_act: gelu
ffn_padding: 'SAME'
use_spk_id: false

###########
# optimization
###########
optimizer_args:
  optimizer_cls: torch.optim.AdamW
  lr: 2.0
  beta1: 0.9
  beta2: 0.98
  weight_decay: 0
lr_scheduler_args:
  scheduler_cls: torch.optim.lr_scheduler.StepLR
  warmup_steps: 2000
  step_size: 50000
  gamma: 0.5
clip_grad_norm: 1
dur_loss: mse # huber|mol

###########
# train and eval
###########
num_ckpt_keep: 3
accumulate_grad_batches: 1
log_interval: 100
num_sanity_val_steps: 5  # steps of validation at the beginning
val_check_interval: 2000
max_updates: 120000
max_batch_frames: 32000
max_batch_size: 100000
max_val_batch_frames: 60000
max_val_batch_size: 1
train_set_name: 'train'
valid_set_name: 'valid'
vocoder: ''
vocoder_ckpt: ''
out_wav_norm: false
save_gt: false
save_f0: false
gen_dir_name: ''
num_valid_plots: 5

###########
# pytorch lightning
# Read https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api for possible values
###########
pl_trainer_accelerator: 'auto'
pl_trainer_devices: 'auto'
pl_trainer_precision: '32-true'
pl_trainer_num_nodes: 1
pl_trainer_strategy: 'auto'
ddp_backend: 'nccl_no_p2p' # choose from 'gloo', 'nccl', 'nccl_no_p2p'
